<!DOCTYPE html><HTML lang="en"><head><meta charset="UTF-8"/><meta content="width=device-width, initial-scale=1.0" name="viewport"/><title>Optimization of Stochastic Differential Equations Â· DiffEqFlux.jl</title><link href="https://diffeqflux.sciml.ai/stable/examples/optimization_sde/" rel="canonical"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script data-main="../../assets/documenter.js" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" data-theme-name="documenter-dark" data-theme-primary-dark="" href="../../assets/themes/documenter-dark.css" rel="stylesheet" type="text/css"/><link class="docs-theme-link" data-theme-name="documenter-light" data-theme-primary="" href="../../assets/themes/documenter-light.css" rel="stylesheet" type="text/css"/><script src="../../assets/themeswap.js"></script><link href="../../assets/favicon.ico" rel="icon" type="image/x-icon"/><script data-outdated-warner="">function maybeAddWarning () {
    const head = document.getElementsByTagName('head')[0];

    // Add a noindex meta tag (unless one exists) so that search engines don't index this version of the docs.
    if (document.body.querySelector('meta[name="robots"]') === null) {
        const meta = document.createElement('meta');
        meta.name = 'robots';
        meta.content = 'noindex';

        head.appendChild(meta);
    };

    // Add a stylesheet to avoid inline styling
    const style = document.createElement('style');
    style.type = 'text/css';
    style.appendChild(document.createTextNode('.outdated-warning-overlay {  position: fixed;  top: 0;  left: 0;  right: 0;  box-shadow: 0 0 10px rgba(0, 0, 0, 0.3);  z-index: 999;  background-color: #ffaba7;  color: rgba(0, 0, 0, 0.7);  border-bottom: 3px solid #da0b00;  padding: 10px 35px;  text-align: center;  font-size: 15px; }  .outdated-warning-overlay .outdated-warning-closer {    position: absolute;    top: calc(50% - 10px);    right: 18px;    cursor: pointer;    width: 12px; }  .outdated-warning-overlay a {    color: #2e63b8; }    .outdated-warning-overlay a:hover {      color: #363636; }'));
    head.appendChild(style);

    const div = document.createElement('div');
    div.classList.add('outdated-warning-overlay');
    const closer = document.createElement('div');
    closer.classList.add('outdated-warning-closer');

    // Icon by font-awesome (license: https://fontawesome.com/license, link: https://fontawesome.com/icons/times?style=solid)
    closer.innerHTML = '<svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="times" class="svg-inline--fa fa-times fa-w-11" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 352 512"><path fill="currentColor" d="M242.72 256l100.07-100.07c12.28-12.28 12.28-32.19 0-44.48l-22.24-22.24c-12.28-12.28-32.19-12.28-44.48 0L176 189.28 75.93 89.21c-12.28-12.28-32.19-12.28-44.48 0L9.21 111.45c-12.28 12.28-12.28 32.19 0 44.48L109.28 256 9.21 356.07c-12.28 12.28-12.28 32.19 0 44.48l22.24 22.24c12.28 12.28 32.2 12.28 44.48 0L176 322.72l100.07 100.07c12.28 12.28 32.2 12.28 44.48 0l22.24-22.24c12.28-12.28 12.28-32.19 0-44.48L242.72 256z"></path></svg>';
    closer.addEventListener('click', function () {
        document.body.removeChild(div);
    });
    let href = '/stable';
    if (window.documenterBaseURL) {
        href = window.documenterBaseURL + '/../stable';
    }
    div.innerHTML = 'This is an old version of the documentation. <br> <a href="' + href + '">Go to the newest version</a>.';
    div.appendChild(closer);
    document.body.appendChild(div);
};

if (document.readyState === 'loading') {
    document.addEventListener('DOMContentLoaded', maybeAddWarning);
} else {
    maybeAddWarning();
};
</script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img alt="DiffEqFlux.jl logo" src="../../assets/logo.png"/></a><div class="docs-package-name"><span class="docs-autofit">DiffEqFlux.jl</span></div><form action="../../search/" class="docs-search"><input class="docs-search-query" id="documenter-search-query" name="q" placeholder="Search docs" type="text"/></form><ul class="docs-menu"><li><a class="tocitem" href="../../">DiffEqFlux.jl: Generalized Physics-Informed and Scientific Machine Learning (SciML)</a></li><li><span class="tocitem">Ordinary Differential Equation (ODE) Tutorials</span><ul><li><a class="tocitem" href="../optimization_ode/">Optimization of Ordinary Differential Equations</a></li><li><a class="tocitem" href="../stiff_ode_fit/">Parameter Estimation on Highly Stiff Systems</a></li><li><a class="tocitem" href="../neural_ode_sciml/">Neural Ordinary Differential Equations with GalacticOptim.jl</a></li><li><a class="tocitem" href="../neural_ode_flux/">Neural Ordinary Differential Equations with Flux.train!</a></li><li><a class="tocitem" href="../mnist_neural_ode/">GPU-based MNIST Neural ODE Classifier</a></li><li><a class="tocitem" href="../augmented_neural_ode/">Augmented Neural Ordinary Differential Equations</a></li><li><a class="tocitem" href="../collocation/">Smoothed Collocation for Fast Two-Stage Training</a></li><li><a class="tocitem" href="../neural_gde/">Neural Graph Differential Equations</a></li><li><a class="tocitem" href="../exogenous_input/">Handling Exogenous Input Signals</a></li><li><a class="tocitem" href="../normalizing_flows/">Continuous Normalizing Flows with GalacticOptim.jl</a></li></ul></li><li><span class="tocitem">Training Techniques</span><ul><li><a class="tocitem" href="../multiple_shooting/">Multiple Shooting</a></li><li><a class="tocitem" href="../local_minima/">Strategies to Avoid Local Minima</a></li><li><a class="tocitem" href="../multiple_nn/">Simultaneous Fitting of Multiple Neural Networks</a></li><li><a class="tocitem" href="../data_parallel/">Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching</a></li><li><a class="tocitem" href="../second_order_neural/">Neural Second Order Ordinary Differential Equation</a></li><li><a class="tocitem" href="../second_order_adjoints/">Newton and Hessian-Free Newton-Krylov with Second Order Adjoint Sensitivity Analysis</a></li><li><a class="tocitem" href="../minibatch/">Training a Neural Ordinary Differential Equation with Mini-Batching</a></li></ul></li><li><span class="tocitem">Stochastic Differential Equation (SDE) Tutorials</span><ul><li class="is-active"><a class="tocitem" href="">Optimization of Stochastic Differential Equations</a><ul class="internal"><li><a class="tocitem" href="#Example-1:-Fitting-Data-with-SDEs-via-Method-of-Moments-and-Parallelism"><span>Example 1: Fitting Data with SDEs via Method of Moments and Parallelism</span></a></li><li><a class="tocitem" href="#Example-2:-Fitting-SDEs-via-Bayesian-Quasi-Likelihood-Approaches"><span>Example 2: Fitting SDEs via Bayesian Quasi-Likelihood Approaches</span></a></li><li><a class="tocitem" href="#Example-3:-Controlling-SDEs-to-an-objective"><span>Example 3: Controlling SDEs to an objective</span></a></li></ul></li><li><a class="tocitem" href="../neural_sde/">Neural Stochastic Differential Equations</a></li></ul></li><li><span class="tocitem">Delay Differential Equation (DDE) Tutorials</span><ul><li><a class="tocitem" href="../delay_diffeq/">Delay Differential Equations</a></li></ul></li><li><span class="tocitem">Differential-Algebraic Equation (DAE) Tutorials</span><ul><li><a class="tocitem" href="../physical_constraints/">Enforcing Physical Constraints via Universal Differential-Algebraic Equations</a></li></ul></li><li><span class="tocitem">Partial Differential Equation (PDE) Tutorials</span><ul><li><a class="tocitem" href="../pde_constrained/">Partial Differential Equation (PDE) Constrained Optimization</a></li></ul></li><li><span class="tocitem">Hybrid and Jump Equation Tutorials</span><ul><li><a class="tocitem" href="../hybrid_diffeq/">Training Neural Networks in Hybrid Differential Equations</a></li><li><a class="tocitem" href="../bouncing_ball/">Bouncing Ball Hybrid ODE Optimization</a></li><li><a class="tocitem" href="../jump/">Neural Jump Diffusions (Neural Jump SDE) and Neural Partial Differential Equations (Neural PDEs)</a></li></ul></li><li><span class="tocitem">Bayesian Estimation Tutorials</span><ul><li><a class="tocitem" href="../turing_bayesian/">Bayesian Estimation of Differential Equations with Probabilistic Programming</a></li><li><a class="tocitem" href="../BayesianNODE_NUTS/">Bayesian Neural ODEs: NUTS</a></li><li><a class="tocitem" href="../BayesianNODE_SGLD/">Bayesian Neural ODEs: SGLD</a></li></ul></li><li><span class="tocitem">Optimal and Model Predictive Control Tutorials</span><ul><li><a class="tocitem" href="../optimal_control/">Solving Optimal Control Problems with Universal Differential Equations</a></li><li><a class="tocitem" href="../feedback_control/">Universal Differential Equations for Neural Feedback Control</a></li><li><a class="tocitem" href="../SDE_control/">Controlling Stochastic Differential Equations</a></li></ul></li><li><span class="tocitem">Universal Differential Equations and Physical Layer Tutorials</span><ul><li><a class="tocitem" href="../universal_diffeq/">Universal Ordinary, Stochastic, and Partial Diffrential Equation Examples</a></li><li><a class="tocitem" href="../tensor_layer/">Physics Informed Machine Learning with TensorLayer</a></li><li><a class="tocitem" href="../hamiltonian_nn/">Hamiltonian Neural Network</a></li></ul></li><li><span class="tocitem">Layer APIs</span><ul><li><a class="tocitem" href="../../layers/BasisLayers/">Classical Basis Layers</a></li><li><a class="tocitem" href="../../layers/TensorLayer/">Tensor Product Layer</a></li><li><a class="tocitem" href="../../layers/CNFLayer/">Continuous Normalizing Flows Layer</a></li><li><a class="tocitem" href="../../layers/SplineLayer/">Spline Layer</a></li><li><a class="tocitem" href="../../layers/NeuralDELayers/">Neural Differential Equation Layers</a></li><li><a class="tocitem" href="../../layers/HamiltonianNN/">Hamiltonian Neural Network Layer</a></li></ul></li><li><span class="tocitem">Manual and APIs</span><ul><li><a class="tocitem" href="../../ControllingAdjoints/">Controlling Choices of Adjoints</a></li><li><a class="tocitem" href="../../Flux/">Use with Flux Chain and train!</a></li><li><a class="tocitem" href="../../FastChain/">FastChain</a></li><li><a class="tocitem" href="../../Collocation/">Smoothed Collocation</a></li><li><a class="tocitem" href="../../GPUs/">GPUs</a></li><li><a class="tocitem" href="../../GalacticOptim/">GalacticOptim.jl</a></li></ul></li><li><a class="tocitem" href="../../Benchmark/">Benchmarks</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Stochastic Differential Equation (SDE) Tutorials</a></li><li class="is-active"><a href="">Optimization of Stochastic Differential Equations</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href="">Optimization of Stochastic Differential Equations</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/SciML/DiffEqFlux.jl/blob/master/docs/src/examples/optimization_sde.md" title="Edit on GitHub"><span class="docs-icon fab">ï</span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" href="#" id="documenter-settings-button" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" href="#" id="documenter-sidebar-button"></a></div></header><article class="content" id="documenter-page"><h1 id="Optimization-of-Stochastic-Differential-Equations"><a class="docs-heading-anchor" href="#Optimization-of-Stochastic-Differential-Equations">Optimization of Stochastic Differential Equations</a><a id="Optimization-of-Stochastic-Differential-Equations-1"></a><a class="docs-heading-anchor-permalink" href="#Optimization-of-Stochastic-Differential-Equations" title="Permalink"></a></h1><p>Here we demonstrate <code>sensealg = ForwardDiffSensitivity()</code> (provided by DiffEqSensitivity.jl) for forward-mode automatic differentiation of a small stochastic differential equation. For large parameter equations, like neural stochastic differential equations, you should use reverse-mode automatic differentiation. However, forward-mode can be more efficient for low numbers of parameters (&lt;100). (Note: the default is reverse-mode AD which is more suitable for things like neural SDEs!)</p><h2 id="Example-1:-Fitting-Data-with-SDEs-via-Method-of-Moments-and-Parallelism"><a class="docs-heading-anchor" href="#Example-1:-Fitting-Data-with-SDEs-via-Method-of-Moments-and-Parallelism">Example 1: Fitting Data with SDEs via Method of Moments and Parallelism</a><a id="Example-1:-Fitting-Data-with-SDEs-via-Method-of-Moments-and-Parallelism-1"></a><a class="docs-heading-anchor-permalink" href="#Example-1:-Fitting-Data-with-SDEs-via-Method-of-Moments-and-Parallelism" title="Permalink"></a></h2><p>Let's do the most common scenario: fitting data. Let's say our ecological system is a stochastic process. Each time we solve this equation we get a different solution, so we need a sensible data source.</p><pre><code class="language-julia">using DiffEqFlux, DifferentialEquations, Plots, Flux, Optim, DiffEqSensitivity
function lotka_volterra!(du,u,p,t)
  x,y = u
  Î±,Î²,Î³,Î´ = p
  du[1] = dx = Î±*x - Î²*x*y
  du[2] = dy = Î´*x*y - Î³*y
end
u0 = [1.0,1.0]
tspan = (0.0,10.0)

function multiplicative_noise!(du,u,p,t)
  x,y = u
  du[1] = p[5]*x
  du[2] = p[6]*y
end
p = [1.5,1.0,3.0,1.0,0.3,0.3]

prob = SDEProblem(lotka_volterra!,multiplicative_noise!,u0,tspan,p)
sol = solve(prob)
plot(sol)</code></pre><p><img alt="" src="https://user-images.githubusercontent.com/1814174/88511873-97bc0a00-cfb3-11ea-8cf5-5930b6575d9d.png"/></p><p>Let's assume that we are observing the seasonal behavior of this system and have 10,000 years of data, corresponding to 10,000 observations of this timeseries. We can utilize this to get the seasonal means and variances. To simulate that scenario, we will generate 10,000 trajectories from the SDE to build our dataset:</p><pre><code class="language-julia">using Statistics
ensembleprob = EnsembleProblem(prob)
@time sol = solve(ensembleprob,SOSRI(),saveat=0.1,trajectories=10_000)
truemean = mean(sol,dims=3)[:,:]
truevar  = var(sol,dims=3)[:,:]</code></pre><p>From here, we wish to utilize the method of moments to fit the SDE's parameters. Thus our loss function will be to solve the SDE a bunch of times and compute moment equations and use these as our loss against the original series. We then plot the evolution of the means and variances to verify the fit. For example:</p><pre><code class="language-julia">function loss(p)
  tmp_prob = remake(prob,p=p)
  ensembleprob = EnsembleProblem(tmp_prob)
  tmp_sol = solve(ensembleprob,SOSRI(),saveat=0.1,trajectories=1000,sensealg=ForwardDiffSensitivity())
  arrsol = Array(tmp_sol)
  sum(abs2,truemean - mean(arrsol,dims=3)) + 0.1sum(abs2,truevar - var(arrsol,dims=3)),arrsol
end

function cb2(p,l,arrsol)
  @show p,l
  means = mean(arrsol,dims=3)[:,:]
  vars = var(arrsol,dims=3)[:,:]
  p1 = plot(sol[1].t,means',lw=5)
  scatter!(p1,sol[1].t,truemean')
  p2 = plot(sol[1].t,vars',lw=5)
  scatter!(p2,sol[1].t,truevar')
  p = plot(p1,p2,layout = (2,1))
  display(p)
  false
end</code></pre><p>We can then use <code>sciml_train</code> to fit the SDE:</p><pre><code class="language-julia">pinit = [1.2,0.8,2.5,0.8,0.1,0.1]
@time res = DiffEqFlux.sciml_train(loss,pinit,ADAM(0.05),cb=cb2,maxiters = 100)</code></pre><p>The final print out was:</p><pre><code class="language-julia">(p, l) = ([1.5242134195974462, 1.019859938499017, 2.9120928257869227, 0.9840408090733335, 0.29427123791721765, 0.3334393815923646], 1.7046719990657184)</code></pre><p>Notice that <strong>both the parameters of the deterministic drift equations and the stochastic portion (the diffusion equation) are fit through this process!</strong> Also notice that the final fit of the moment equations is close:</p><p><img alt="" src="https://user-images.githubusercontent.com/1814174/88511872-97bc0a00-cfb3-11ea-9d44-a3ed96a77df9.png"/></p><p>The time for the full fitting process was:</p><pre><code class="language-none">250.654845 seconds (4.69 G allocations: 104.868 GiB, 11.87% gc time)</code></pre><p>approximately 4 minutes.</p><h2 id="Example-2:-Fitting-SDEs-via-Bayesian-Quasi-Likelihood-Approaches"><a class="docs-heading-anchor" href="#Example-2:-Fitting-SDEs-via-Bayesian-Quasi-Likelihood-Approaches">Example 2: Fitting SDEs via Bayesian Quasi-Likelihood Approaches</a><a id="Example-2:-Fitting-SDEs-via-Bayesian-Quasi-Likelihood-Approaches-1"></a><a class="docs-heading-anchor-permalink" href="#Example-2:-Fitting-SDEs-via-Bayesian-Quasi-Likelihood-Approaches" title="Permalink"></a></h2><p>An inference method which can be much more efficient in many cases is the quasi-likelihood appraoch. This approach matches the random likelihood of the SDE output with the random sampling of a Bayesian inference problem to more efficiently directly estimate the posterior distribution. For more information, please see <a href="https://github.com/TuringLang/TuringTutorials/blob/master/10_diffeq.ipynb">the Turing.jl Bayesian Differential Equations tutorial</a></p><h2 id="Example-3:-Controlling-SDEs-to-an-objective"><a class="docs-heading-anchor" href="#Example-3:-Controlling-SDEs-to-an-objective">Example 3: Controlling SDEs to an objective</a><a id="Example-3:-Controlling-SDEs-to-an-objective-1"></a><a class="docs-heading-anchor-permalink" href="#Example-3:-Controlling-SDEs-to-an-objective" title="Permalink"></a></h2><p>In this example, we will find the parameters of the SDE that force the solution to be close to the constant 1.</p><pre><code class="language-julia">using DifferentialEquations, Flux, Optim, DiffEqFlux, DiffEqSensitivity, Plots

function lotka_volterra!(du, u, p, t)
  x, y = u
  Î±, Î², Î´, Î³ = p
  du[1] = dx = Î±*x - Î²*x*y
  du[2] = dy = -Î´*y + Î³*x*y
end

function lotka_volterra_noise!(du, u, p, t)
  du[1] = 0.1u[1]
  du[2] = 0.1u[2]
end

u0 = [1.0,1.0]
tspan = (0.0, 10.0)
p = [2.2, 1.0, 2.0, 0.4]
prob_sde = SDEProblem(lotka_volterra!, lotka_volterra_noise!, u0, tspan)


function predict_sde(p)
  return Array(solve(prob_sde, SOSRI(), p=p,
               sensealg = ForwardDiffSensitivity(), saveat = 0.1))
end

loss_sde(p) = sum(abs2, x-1 for x in predict_sde(p))</code></pre><p>For this training process, because the loss function is stochastic, we will use the <code>ADAM</code> optimizer from Flux.jl. The <code>sciml_train</code> function is the same as before. However, to speed up the training process, we will use a global counter so that way we only plot the current results every 10 iterations. This looks like:</p><pre><code class="language-julia">callback = function (p, l)
  display(l)
  remade_solution = solve(remake(prob_sde, p = p), SOSRI(), saveat = 0.1)
  plt = plot(remade_solution, ylim = (0, 6))
  display(plt)
  return false
end</code></pre><p>Let's optimize</p><pre><code class="language-julia">result_sde = DiffEqFlux.sciml_train(loss_sde, p, ADAM(0.1),
                                    cb = callback, maxiters = 100)</code></pre><p><img alt="" src="https://user-images.githubusercontent.com/1814174/51399524-2c6abf80-1b14-11e9-96ae-0192f7debd03.gif"/></p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../minibatch/">Â« Training a Neural Ordinary Differential Equation with Mini-Batching</a><a class="docs-footer-nextpage" href="../neural_sde/">Neural Stochastic Differential Equations Â»</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label></p><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div><p></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Sunday 11 April 2021 23:01">Sunday 11 April 2021</span>. Using Julia version 1.6.0.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></HTML>
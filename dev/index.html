<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Home · DiffEqFlux.jl</title><link rel="canonical" href="https://diffeqflux.sciml.ai/stable/"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="assets/documenter.js"></script><script src="siteinfo.js"></script><script src="../versions.js"></script><link href="assets/favicon.ico" rel="icon" type="image/x-icon"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-dark.css" data-theme-name="documenter-dark"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href><img src="assets/logo.png" alt="DiffEqFlux.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit">DiffEqFlux.jl</span></div><form class="docs-search" action="search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li class="is-active"><a class="tocitem" href>Home</a><ul class="internal"><li><a class="tocitem" href="#Basics-1"><span>Basics</span></a></li><li><a class="tocitem" href="#Applications-1"><span>Applications</span></a></li><li><a class="tocitem" href="#Citation-1"><span>Citation</span></a></li></ul></li><li><span class="tocitem">Tutorials</span><ul><li><a class="tocitem" href="examples/optimization_ode/">Optimization of Ordinary Differential Equations</a></li><li><a class="tocitem" href="examples/optimization_sde/">Optimization of Stochastic Differential Equations</a></li><li><a class="tocitem" href="examples/lotka_volterra/">Lotka-Volterra with Flux.train!</a></li><li><a class="tocitem" href="examples/delay_diffeq/">Delay Differential Equations</a></li><li><a class="tocitem" href="examples/neural_ode_sciml/">Neural Ordinary Differential Equations with sciml_train</a></li><li><a class="tocitem" href="examples/neural_ode_flux/">Neural Ordinary Differential Equations with Flux.train!</a></li><li><a class="tocitem" href="examples/mnist_neural_ode/">GPU-based MNIST Neural ODE Classifier</a></li><li><a class="tocitem" href="examples/augmented_neural_ode/">Augmented Neural Ordinary Differential Equations</a></li><li><a class="tocitem" href="examples/normalizing_flows/">Continuous Normalizing Flows with sciml_train</a></li><li><a class="tocitem" href="examples/local_minima/">Strategies to Avoid Local Minima</a></li><li><a class="tocitem" href="examples/neural_sde/">Neural Stochastic Differential Equations</a></li><li><a class="tocitem" href="examples/collocation/">Smoothed Collocation for Fast Two-Stage Training</a></li><li><a class="tocitem" href="examples/pde_constrained/">Partial Differential Equation Constrained Optimization</a></li><li><a class="tocitem" href="examples/optimal_control/">Solving Optimal Control Problems with Universal Differential Equations</a></li><li><a class="tocitem" href="examples/feedback_control/">Universal Differential Equations for Neural Feedback Control</a></li><li><a class="tocitem" href="examples/second_order_neural/">Neural Second Order Ordinary Differential Equation</a></li><li><a class="tocitem" href="examples/physical_constraints/">Enforcing Physical Constraints via Universal Differential-Algebraic Equations</a></li><li><a class="tocitem" href="examples/second_order_adjoints/">Newton and Hessian-Free Newton-Krylov with Second Order Adjoint Sensitivity Analysis</a></li><li><a class="tocitem" href="examples/jump/">Neural Jump Diffusions (Neural Jump SDE) and Neural Partial Differential Equations (Neural PDEs)</a></li><li><a class="tocitem" href="examples/universal_diffeq/">Universal Ordinary, Stochastic, and Partial Diffrential Equation Examples</a></li><li><a class="tocitem" href="examples/minibatch/">Training a Neural Ordinary Differential Equation with Mini-Batching</a></li><li><a class="tocitem" href="examples/tensor_layer/">Physics Informed Machine Learning with TensorLayer</a></li><li><a class="tocitem" href="examples/neural_gde/">Neural Graph Differential Equations</a></li></ul></li><li><span class="tocitem">Layers</span><ul><li><a class="tocitem" href="layers/BasisLayers/">Classical Basis Layers</a></li><li><a class="tocitem" href="layers/TensorLayer/">Tensor Product Layer</a></li><li><a class="tocitem" href="layers/CNFLayer/">Continuous Normalizing Flows Layer</a></li><li><a class="tocitem" href="layers/SplineLayer/">Spline Layer</a></li><li><a class="tocitem" href="layers/NeuralDELayers/">Neural Differential Equation Layers</a></li></ul></li><li><a class="tocitem" href="ControllingAdjoints/">Controlling Choices of Adjoints</a></li><li><a class="tocitem" href="Flux/">Use with Flux Chain and train!</a></li><li><a class="tocitem" href="FastChain/">FastChain</a></li><li><a class="tocitem" href="Collocation/">Smoothed Collocation</a></li><li><a class="tocitem" href="GPUs/">GPUs</a></li><li><a class="tocitem" href="Scimltrain/">sciml_train</a></li><li><a class="tocitem" href="Benchmark/">Benchmark</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Home</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Home</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/SciML/DiffEqFlux.jl/blob/master/docs/src/index.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="DiffEqFlux-1"><a class="docs-heading-anchor" href="#DiffEqFlux-1">DiffEqFlux</a><a class="docs-heading-anchor-permalink" href="#DiffEqFlux-1" title="Permalink"></a></h1><p>DiffEqFlux.jl is not just for neural ordinary differential equations. DiffEqFlux.jl is for universal differential equations, where these can include delays, physical constraints, stochasticity, events, and all other kinds of interesting behavior that shows up in scientific simulations. Neural networks can be all or part of the model. They can be around the differential equation, in the cost function, or inside of the differential equation. Neural networks representing unknown portions of the model or functions can go anywhere you have uncertainty in the form of the scientific simulator. For an overview of the topic with applications, consult the paper <a href="https://arxiv.org/abs/2001.04385">Universal Differential Equations for Scientific Machine Learning</a>.</p><p>As such, it is the first package to support and demonstrate:</p><ul><li>Stiff universal ordinary differential equations (universal ODEs)</li><li>Universal stochastic differential equations (universal SDEs)</li><li>Universal delay differential equations (universal DDEs)</li><li>Universal partial differential equations (universal PDEs)</li><li>Universal jump stochastic differential equations (universal jump diffusions)</li><li>Hybrid universal differential equations (universal DEs with event handling)</li></ul><p>with high order, adaptive, implicit, GPU-accelerated, Newton-Krylov, etc. methods. For examples, please refer to <a href="https://julialang.org/blog/2019/01/fluxdiffeq">the release blog post</a> (which we try to keep updated for changes to the libraries). Additional demonstrations, like neural PDEs and neural jump SDEs, can be found <a href="http://www.stochasticlifestyle.com/neural-jump-sdes-jump-diffusions-and-neural-pdes/">at this blog post</a> (among many others!).</p><p>Many different training techniques are supported by this package, including:</p><ul><li>Optimize-then-discretize (backsolve adjoints, checkpointed adjoints, quadrature adjoints)</li><li>Discretize-then-optimize (forward and reverse mode discrete sensitivity analysis)<ul><li>This is a generalization of <a href="https://arxiv.org/pdf/1902.10298.pdf">ANODE</a> and <a href="https://arxiv.org/pdf/1906.04596.pdf">ANODEv2</a> to all <a href="https://docs.sciml.ai/latest/solvers/ode_solve/">DifferentialEquations.jl ODE solvers</a></li></ul></li><li>Hybrid approaches (adaptive time stepping + AD for adaptive discretize-then-optimize)</li><li>Collocation approaches (two-stage methods, multiple shooting, etc.)</li></ul><p>For more details on the adjoint sensitivity analysis methods for computing fast gradients, see the <a href="ControllingAdjoints/#adjoints-1">Adjoints page</a>.</p><p>With this package, you can explore various ways to integrate the two methodologies:</p><ul><li>Neural networks can be defined where the “activations” are nonlinear functions described by differential equations</li><li>Neural networks can be defined where some layers are ODE solves</li><li>ODEs can be defined where some terms are neural networks</li><li>Cost functions on ODEs can define neural networks</li></ul><h2 id="Basics-1"><a class="docs-heading-anchor" href="#Basics-1">Basics</a><a class="docs-heading-anchor-permalink" href="#Basics-1" title="Permalink"></a></h2><p>The basics are all provided by the <a href="https://docs.sciml.ai/latest/">DifferentialEquations.jl</a> package. Specifically, <a href="https://docs.sciml.ai/latest/analysis/sensitivity/">the <code>solve</code> function is automatically compatible with AD systems like Zygote.jl</a> and thus there is no machinery that is necessary to use DifferentialEquations.jl package. For example, the following computes the solution to an ODE and computes the gradient of a loss function (the sum of the ODE&#39;s output at each timepoint with dt=0.1) via the adjoint method:</p><pre><code class="language-julia">using DiffEqSensitivity, OrdinaryDiffEq, Zygote

function fiip(du,u,p,t)
  du[1] = dx = p[1]*u[1] - p[2]*u[1]*u[2]
  du[2] = dy = -p[3]*u[2] + p[4]*u[1]*u[2]
end
p = [1.5,1.0,3.0,1.0]; u0 = [1.0;1.0]
prob = ODEProblem(fiip,u0,(0.0,10.0),p)
sol = solve(prob,Tsit5())
loss(u0,p) = sum(solve(prob,Tsit5(),u0=u0,p=p,saveat=0.1))
du01,dp1 = Zygote.gradient(loss,u0,p)</code></pre><p>Thus, what DiffEqFlux.jl provides is:</p><ul><li>A bunch of tutorials, documentation, and test cases for this combination with neural network libraries and GPUs</li><li>Pre-built layer functions for common use cases, like neural ODEs</li><li>Specialized layer functions (<code>FastDense</code>) to improve neural differential equation training performance</li><li>A specialized optimization function <code>sciml_train</code> with a training loop that allows non-machine learning libraries to be easily utilized</li></ul><h2 id="Applications-1"><a class="docs-heading-anchor" href="#Applications-1">Applications</a><a class="docs-heading-anchor-permalink" href="#Applications-1" title="Permalink"></a></h2><p>The approach of this package is the efficient training of <a href="https://arxiv.org/abs/2001.04385">Universal Differential Equations</a>. Since this is a fairly general class of problems, the following applications are readily available as specific instances of this methodology, and are showcased in tutorials and layer functions:</p><ul><li>Neural ODEs</li><li>Neural SDEs</li><li>Neural DAEs</li><li>Neural DDEs</li><li>Augmented Neural ODEs</li><li>Graph Neural ODEs</li><li>Hamiltonian Neural Networks (with specialized second order and symplectic integrators)</li><li>Legrangian Neural Networks</li><li>Continuous Normalizing Flows (CNF) and FFJORD</li><li>Galerkin Nerual ODEs</li></ul><h2 id="Citation-1"><a class="docs-heading-anchor" href="#Citation-1">Citation</a><a class="docs-heading-anchor-permalink" href="#Citation-1" title="Permalink"></a></h2><p>If you use DiffEqFlux.jl or are influenced by its ideas, please cite:</p><pre><code class="language-none">@article{rackauckas2020universal,
  title={Universal differential equations for scientific machine learning},
  author={Rackauckas, Christopher and Ma, Yingbo and Martensen, Julius and Warner, Collin and Zubov, Kirill and Supekar, Rohit and Skinner, Dominic and Ramadhan, Ali},
  journal={arXiv preprint arXiv:2001.04385},
  year={2020}
}</code></pre></article><nav class="docs-footer"><a class="docs-footer-nextpage" href="examples/optimization_ode/">Optimization of Ordinary Differential Equations »</a></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Thursday 16 July 2020 11:26">Thursday 16 July 2020</span>. Using Julia version 1.4.2.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>

<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Use sciml_train to train a neural network on a stiff chemical reaction system · DiffEqFlux.jl</title><link rel="canonical" href="https://diffeqflux.sciml.ai/stable/examples/neural_stiff_ode_sciml/"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link href="../../assets/favicon.ico" rel="icon" type="image/x-icon"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.png" alt="DiffEqFlux.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit">DiffEqFlux.jl</span></div><form class="docs-search" action="../../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../../">DiffEqFlux.jl: Generalized Physics-Informed and Scientific Machine Learning (SciML)</a></li><li><span class="tocitem">Basic Parameter Fitting Tutorials</span><ul><li><a class="tocitem" href="../optimization_ode/">Optimization of Ordinary Differential Equations</a></li><li><a class="tocitem" href="../optimization_sde/">Optimization of Stochastic Differential Equations</a></li><li><a class="tocitem" href="../lotka_volterra/">Lotka-Volterra with Flux.train!</a></li><li><a class="tocitem" href="../delay_diffeq/">Delay Differential Equations</a></li><li><a class="tocitem" href="../pde_constrained/">Partial Differential Equation Constrained Optimization</a></li></ul></li><li><span class="tocitem">Neural ODE and SDE Tutorials</span><ul><li><a class="tocitem" href="../neural_ode_sciml/">Neural Ordinary Differential Equations with sciml_train</a></li><li><a class="tocitem" href="../neural_ode_flux/">Neural Ordinary Differential Equations with Flux.train!</a></li><li><a class="tocitem" href="../mnist_neural_ode/">GPU-based MNIST Neural ODE Classifier</a></li><li><a class="tocitem" href="../neural_sde/">Neural Stochastic Differential Equations</a></li><li><a class="tocitem" href="../augmented_neural_ode/">Augmented Neural Ordinary Differential Equations</a></li><li><a class="tocitem" href="../collocation/">Smoothed Collocation for Fast Two-Stage Training</a></li><li><a class="tocitem" href="../neural_gde/">Neural Graph Differential Equations</a></li><li><a class="tocitem" href="../normalizing_flows/">Continuous Normalizing Flows with sciml_train</a></li></ul></li><li><span class="tocitem">Bayesian Estimation Tutorials</span><ul><li><a class="tocitem" href="../turing_bayesian/">Bayesian Estimation of Differential Equations with Probabilistic Programming</a></li><li><a class="tocitem" href="../BayesianNODE_NUTS/">Bayesian Neural ODEs: NUTS</a></li><li><a class="tocitem" href="../BayesianNODE_SGLD/">Bayesian Neural ODEs: SGLD</a></li></ul></li><li><span class="tocitem">FAQ, Tips, and Tricks</span><ul><li><a class="tocitem" href="../local_minima/">Strategies to Avoid Local Minima</a></li><li><a class="tocitem" href="../multiple_nn/">Simultaneous Fitting of Multiple Neural Networks</a></li><li><a class="tocitem" href="../data_parallel/">Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching</a></li><li><a class="tocitem" href="../second_order_neural/">Neural Second Order Ordinary Differential Equation</a></li><li><a class="tocitem" href="../second_order_adjoints/">Newton and Hessian-Free Newton-Krylov with Second Order Adjoint Sensitivity Analysis</a></li><li><a class="tocitem" href="../minibatch/">Training a Neural Ordinary Differential Equation with Mini-Batching</a></li></ul></li><li><span class="tocitem">Hybrid and Jump Tutorials</span><ul><li><a class="tocitem" href="../hybrid_diffeq/">Training Neural Networks in Hybrid Differential Equations</a></li><li><a class="tocitem" href="../bouncing_ball/">Bouncing Ball Hybrid ODE Optimization</a></li><li><a class="tocitem" href="../jump/">Neural Jump Diffusions (Neural Jump SDE) and Neural Partial Differential Equations (Neural PDEs)</a></li></ul></li><li><span class="tocitem">Optimal and Model Predictive Control Tutorials</span><ul><li><a class="tocitem" href="../optimal_control/">Solving Optimal Control Problems with Universal Differential Equations</a></li><li><a class="tocitem" href="../feedback_control/">Universal Differential Equations for Neural Feedback Control</a></li></ul></li><li><span class="tocitem">Universal Differential Equations and Physical Constraints Tutorials</span><ul><li><a class="tocitem" href="../universal_diffeq/">Universal Ordinary, Stochastic, and Partial Diffrential Equation Examples</a></li><li><a class="tocitem" href="../exogenous_input/">Handling Exogenous Input Signals</a></li><li><a class="tocitem" href="../physical_constraints/">Enforcing Physical Constraints via Universal Differential-Algebraic Equations</a></li><li><a class="tocitem" href="../tensor_layer/">Physics Informed Machine Learning with TensorLayer</a></li><li><a class="tocitem" href="../hamiltonian_nn/">Hamiltonian Neural Network</a></li></ul></li><li><span class="tocitem">Layers</span><ul><li><a class="tocitem" href="../../layers/BasisLayers/">Classical Basis Layers</a></li><li><a class="tocitem" href="../../layers/TensorLayer/">Tensor Product Layer</a></li><li><a class="tocitem" href="../../layers/CNFLayer/">Continuous Normalizing Flows Layer</a></li><li><a class="tocitem" href="../../layers/SplineLayer/">Spline Layer</a></li><li><a class="tocitem" href="../../layers/NeuralDELayers/">Neural Differential Equation Layers</a></li><li><a class="tocitem" href="../../layers/HamiltonianNN/">Hamiltonian Neural Network Layer</a></li></ul></li><li><a class="tocitem" href="../../ControllingAdjoints/">Controlling Choices of Adjoints</a></li><li><a class="tocitem" href="../../Flux/">Use with Flux Chain and train!</a></li><li><a class="tocitem" href="../../FastChain/">FastChain</a></li><li><a class="tocitem" href="../../Collocation/">Smoothed Collocation</a></li><li><a class="tocitem" href="../../GPUs/">GPUs</a></li><li><a class="tocitem" href="../../Scimltrain/">sciml_train</a></li><li><a class="tocitem" href="../../Benchmark/">Benchmark</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Use sciml_train to train a neural network on a stiff chemical reaction system</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Use sciml_train to train a neural network on a stiff chemical reaction system</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/SciML/DiffEqFlux.jl/blob/master/docs/src/examples/neural_stiff_ode_sciml.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Use-sciml_train-to-train-a-neural-network-on-a-stiff-chemical-reaction-system-1"><a class="docs-heading-anchor" href="#Use-sciml_train-to-train-a-neural-network-on-a-stiff-chemical-reaction-system-1">Use sciml_train to train a neural network on a stiff chemical reaction system</a><a class="docs-heading-anchor-permalink" href="#Use-sciml_train-to-train-a-neural-network-on-a-stiff-chemical-reaction-system-1" title="Permalink"></a></h1><p>This tutorial goes into the training of stiff ODEs. Please read the <a href="https://diffeqflux.sciml.ai/dev/examples/neural_ode_sciml/">neural ordinary differential equations tutorial</a> first.</p><h2 id="Copy-Pasteable-Code-1"><a class="docs-heading-anchor" href="#Copy-Pasteable-Code-1">Copy-Pasteable Code</a><a class="docs-heading-anchor-permalink" href="#Copy-Pasteable-Code-1" title="Permalink"></a></h2><p>Before getting to the explanation, here&#39;s some code to start with. We will follow a full explanation of the definition and training process:</p><pre><code class="language-julia">using Flux, DiffEqFlux, OrdinaryDiffEq, Optim, Plots, Random, DiffEqSensitivity

using ForwardDiff

function f!(du,u,p,t)
  y₁,y₃ = u
  k₁,k₂,k₃ = p
  y₂ = 1 - (y₁+y₃)
  du[1] = -k₁*y₁+k₃*y₂*y₃
  du[2] =  k₂*y₂^2
  nothing
end

u₀ = [1.0, 0]

tspan = (0.0, 1e5)
p = [0.04, 3e7, 1e4]
datasize = 100
t = range(tspan[1], tspan[2], length = datasize)

stiff_func = ODEFunction(f!)
prob_stiff = ODEProblem(stiff_func, u₀, tspan, p)
sol_stiff = solve(prob_stiff, Rodas5(), saveat = t)
sol_stiff_data = Array(sol_stiff)

nn_dudt2 = FastChain(FastDense(2, 4, tanh, initW = (m, n) -&gt; 1e-5rand(MersenneTwister(1), m, n)),
                     FastDense(4, 2, initW = (m, n) -&gt; 1e-5rand(MersenneTwister(3), m, n)))

model_stiff_node = NeuralODE(nn_dudt2,
                             tspan, Tsit5(), saveat = sol_stiff.t,
                             reltol = 1e-3,
                             abstol = 1e-6,
                             maxiters = 1000,
                             sensealg = QuadratureAdjoint(),
                             verbose=false) # Tsit5 is good enough here
model_stiff_node(u₀)

function predict_stiff_node(p)
    return model_stiff_node(u₀, p)
end

function loss_stiff_node(p)
    prediction = predict_stiff_node(p)
    loss = sqrt(sum(abs2, sol_stiff_data .- prediction))
    return loss, prediction
end

callback = function (p, l, pred) #callback function to observe training
  display(l)
  return false
end

l1 = first(loss_stiff_node(model_stiff_node.p))
pp = model_stiff_node.p
for _ in 1:5
  global pp
  result_lbfgs = DiffEqFlux.sciml_train(loss_stiff_node, pp,
                                        LBFGS(),
                                        cb = callback, maxiters = 100)
  pp = result_lbfgs.minimizer
end
plot(plot(sol_stiff, lab=false, title=&quot;Ground truth&quot;), plot(predict_stiff_node(pp), lab=false, title=&quot;Prediction&quot;))</code></pre><p>![rober fitting]((https://user-images.githubusercontent.com/17304743/102832372-28a8dd00-43bc-11eb-93de-36166e8b17cf.png)</p><h2 id="Explanation-1"><a class="docs-heading-anchor" href="#Explanation-1">Explanation</a><a class="docs-heading-anchor-permalink" href="#Explanation-1" title="Permalink"></a></h2><p>First, let&#39;s get a time series array from the Robertson&#39;s equation as data. Note that since <code>y₂</code> has the fastest rate, we want to eliminate it from our training. We know the conservation law <code>y₁(t) + y₂(t) + y₃(t) = 1</code> for all <code>t</code>. Hence, we can always compute <code>y₂</code> from <code>y₁</code> and <code>y₃</code>.</p><pre><code class="language-julia">using Flux, DiffEqFlux, OrdinaryDiffEq, Optim, Plots, Random, DiffEqSensitivity

using ForwardDiff

function f!(du,u,p,t)
  y₁,y₃ = u
  k₁,k₂,k₃ = p
  y₂ = 1 - (y₁+y₃)
  du[1] = -k₁*y₁+k₃*y₂*y₃
  du[2] =  k₂*y₂^2
  nothing
end

u₀ = [1.0, 0]

tspan = (0.0, 1e5)
p = [0.04, 3e7, 1e4]
datasize = 100
t = range(tspan[1], tspan[2], length = datasize)

stiff_func = ODEFunction(f!)
prob_stiff = ODEProblem(stiff_func, u₀, tspan, p)
sol_stiff = solve(prob_stiff, Rodas5(), saveat = t)
sol_stiff_data = Array(sol_stiff)</code></pre><p>Now let&#39;s define a neural network with a <code>NeuralODE</code> layer. First we define the layer. Here we&#39;re going to use <code>FastChain</code>, which is a faster neural network structure for NeuralODEs. Since we reduced the fastest rate, the system is not very stiff anymore. We can use <code>Tsit5()</code> non-stiff solver to fit this model for better efficiency.</p><pre><code class="language-julia">nn_dudt2 = FastChain(FastDense(2, 4, tanh, initW = (m, n) -&gt; 1e-5rand(MersenneTwister(1), m, n)),
                     FastDense(4, 2, initW = (m, n) -&gt; 1e-5rand(MersenneTwister(3), m, n)))

model_stiff_node = NeuralODE(nn_dudt2,
                             tspan, Tsit5(), saveat = sol_stiff.t,
                             reltol = 1e-3,
                             abstol = 1e-6,
                             maxiters = 1000,
                             sensealg = QuadratureAdjoint(),
                             verbose=false) # Tsit5 is good enough here</code></pre><p>From here we build a loss function around it. The <code>NeuralODE</code> has an optional second argument for new parameters which we will use to iteratively change the neural network in our training loop. We will use the L2 loss of the network&#39;s output against the time series data:</p><pre><code class="language-julia">function predict_stiff_node(p)
    return model_stiff_node(u₀, p)
end

function loss_stiff_node(p)
    prediction = predict_stiff_node(p)
    loss = sqrt(sum(abs2, sol_stiff_data .- prediction))
    return loss, prediction
end</code></pre><p>We define a callback function.</p><pre><code class="language-julia">callback = function (p, l, pred) #callback function to observe training
  display(l)
  return false
end</code></pre><p>We then train the neural network to learn the ODE. Here, we use the <code>LBFGS</code> optimizer, because it yields the best result empirically.</p><pre><code class="language-julia">pp = model_stiff_node.p
for _ in 1:5
  global pp
  result_lbfgs = DiffEqFlux.sciml_train(loss_stiff_node, pp,
                                        LBFGS(),
                                        cb = callback, maxiters = 100)
  pp = result_lbfgs.minimizer
end</code></pre><p>Finally, we can plot the result.</p><pre><code class="language-julia">plot(plot(sol_stiff, lab=false, title=&quot;Ground truth&quot;), plot(predict_stiff_node(pp), lab=false, title=&quot;Prediction&quot;))</code></pre></article></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Tuesday 22 December 2020 00:56">Tuesday 22 December 2020</span>. Using Julia version 1.4.2.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
